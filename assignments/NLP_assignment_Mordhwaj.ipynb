{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7294aa61",
   "metadata": {},
   "source": [
    "# Problem 1 : NLP text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93a46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem Statement: NLP text processing\n",
    " \n",
    "# Write a Python program that reads the demotext.txt text file. The  following  are  the  tasks  that  are  to  be  taken  into  consideration  while constructing the solution for text processing using the NLTK library.\n",
    "\n",
    "# 1.Load the demotext.txt text file into a variable and then close the file\n",
    "\n",
    "# 2.Do word-wise tokenization list out generated tokens\n",
    "\n",
    "# 3.Transform each token into a small case\n",
    "\n",
    "# 4.Remove stop words from the generated token list\n",
    "\n",
    "# 5.Remove extra symbols like commas, full stops, and question marks using a regular expression tokenizer and store them in anothervariable\n",
    "\n",
    "# 6.Do bigram and trigram for generated tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86076cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Lorem Ipsum?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lorem Ipsum is simply dummy text of the printi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>typesetting industry. Lorem Ipsum has been the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>standard dummy text ever since the 1500s, when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>printer took a galley of type and scrambled it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>type specimen book. It has survived not only f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>but also the leap into electronic typesetting,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>remaining essentially unchanged.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It was popularised in the 1960s with the relea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sheets containing Lorem Ipsum passages, and mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>with desktop publishing software like Aldus Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>including versions of Lorem Ipsum.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0                                What is Lorem Ipsum?\n",
       "1   Lorem Ipsum is simply dummy text of the printi...\n",
       "2   typesetting industry. Lorem Ipsum has been the...\n",
       "3   standard dummy text ever since the 1500s, when...\n",
       "4   printer took a galley of type and scrambled it...\n",
       "5   type specimen book. It has survived not only f...\n",
       "6     but also the leap into electronic typesetting, \n",
       "7                   remaining essentially unchanged. \n",
       "8   It was popularised in the 1960s with the relea...\n",
       "9   sheets containing Lorem Ipsum passages, and mo...\n",
       "10  with desktop publishing software like Aldus Pa...\n",
       "11                 including versions of Lorem Ipsum."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# data=pd.read_csv(\"demotext.txt\", delimiter = \"\\t\")\n",
    "# data\n",
    "data = pd.read_csv(\"demotext.txt\", delimiter=\"\\t\", header=None, names=[\"text\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d066515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "\n",
    "tokenized_text = data[\"text\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "781c8477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           [What, is, Lorem, Ipsum, ?]\n",
       "1     [Lorem, Ipsum, is, simply, dummy, text, of, th...\n",
       "2     [typesetting, industry, ., Lorem, Ipsum, has, ...\n",
       "3     [standard, dummy, text, ever, since, the, 1500...\n",
       "4     [printer, took, a, galley, of, type, and, scra...\n",
       "5     [type, specimen, book, ., It, has, survived, n...\n",
       "6     [but, also, the, leap, into, electronic, types...\n",
       "7                [remaining, essentially, unchanged, .]\n",
       "8     [It, was, popularised, in, the, 1960s, with, t...\n",
       "9     [sheets, containing, Lorem, Ipsum, passages, ,...\n",
       "10    [with, desktop, publishing, software, like, Al...\n",
       "11           [including, versions, of, Lorem, Ipsum, .]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e7524fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           [what, is, lorem, ipsum, ?]\n",
       "1     [lorem, ipsum, is, simply, dummy, text, of, th...\n",
       "2     [typesetting, industry, ., lorem, ipsum, has, ...\n",
       "3     [standard, dummy, text, ever, since, the, 1500...\n",
       "4     [printer, took, a, galley, of, type, and, scra...\n",
       "5     [type, specimen, book, ., it, has, survived, n...\n",
       "6     [but, also, the, leap, into, electronic, types...\n",
       "7                [remaining, essentially, unchanged, .]\n",
       "8     [it, was, popularised, in, the, 1960s, with, t...\n",
       "9     [sheets, containing, lorem, ipsum, passages, ,...\n",
       "10    [with, desktop, publishing, software, like, al...\n",
       "11           [including, versions, of, lorem, ipsum, .]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform each token into lowercase\n",
    "tokenized_text_lowercase = tokenized_text.apply(lambda x: [word.lower() for word in x])\n",
    "tokenized_text_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12e02981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     [lorem, ipsum, ?]\n",
       "1         [lorem, ipsum, simply, dummy, text, printing]\n",
       "2     [typesetting, industry, ., lorem, ipsum, indus...\n",
       "3     [standard, dummy, text, ever, since, 1500s, ,,...\n",
       "4        [printer, took, galley, type, scrambled, make]\n",
       "5     [type, specimen, book, ., survived, five, cent...\n",
       "6              [also, leap, electronic, typesetting, ,]\n",
       "7                [remaining, essentially, unchanged, .]\n",
       "8               [popularised, 1960s, release, letraset]\n",
       "9     [sheets, containing, lorem, ipsum, passages, ,...\n",
       "10    [desktop, publishing, software, like, aldus, p...\n",
       "11               [including, versions, lorem, ipsum, .]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# list of english stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stop words from the tokenized text\n",
    "tokenized_text_no_stopwords = tokenized_text_lowercase.apply(lambda x: [word for word in x if word not in stop_words])\n",
    "tokenized_text_no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb91fad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        [lorem, ipsum]\n",
       "1         [lorem, ipsum, simply, dummy, text, printing]\n",
       "2     [typesetting, industry, lorem, ipsum, industry...\n",
       "3     [standard, dummy, text, ever, since, 1500s, un...\n",
       "4        [printer, took, galley, type, scrambled, make]\n",
       "5     [type, specimen, book, survived, five, centuries]\n",
       "6                 [also, leap, electronic, typesetting]\n",
       "7                   [remaining, essentially, unchanged]\n",
       "8               [popularised, 1960s, release, letraset]\n",
       "9     [sheets, containing, lorem, ipsum, passages, r...\n",
       "10    [desktop, publishing, software, like, aldus, p...\n",
       "11                  [including, versions, lorem, ipsum]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regular expression to remove punctuation\n",
    "tokenizer = RegexpTokenizer(r'\\b\\w+\\b')\n",
    "\n",
    "tokenized_text_no_symbols = tokenized_text_no_stopwords.apply(lambda x: tokenizer.tokenize(' '.join(x)))\n",
    "tokenized_text_no_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ae9341b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      [(lorem, ipsum)]\n",
       "1     [(lorem, ipsum), (ipsum, simply), (simply, dum...\n",
       "2     [(typesetting, industry), (industry, lorem), (...\n",
       "3     [(standard, dummy), (dummy, text), (text, ever...\n",
       "4     [(printer, took), (took, galley), (galley, typ...\n",
       "5     [(type, specimen), (specimen, book), (book, su...\n",
       "6     [(also, leap), (leap, electronic), (electronic...\n",
       "7     [(remaining, essentially), (essentially, uncha...\n",
       "8     [(popularised, 1960s), (1960s, release), (rele...\n",
       "9     [(sheets, containing), (containing, lorem), (l...\n",
       "10    [(desktop, publishing), (publishing, software)...\n",
       "11    [(including, versions), (versions, lorem), (lo...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "# fn to generate ngrams for a list of tokens\n",
    "def generate_ngrams(tokens, n):\n",
    "    return list(ngrams(tokens, n))\n",
    "\n",
    "bigrams = tokenized_text_no_symbols.apply(lambda x: generate_ngrams(x, 2))\n",
    "bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8433002f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                    []\n",
       "1     [(lorem, ipsum, simply), (ipsum, simply, dummy...\n",
       "2     [(typesetting, industry, lorem), (industry, lo...\n",
       "3     [(standard, dummy, text), (dummy, text, ever),...\n",
       "4     [(printer, took, galley), (took, galley, type)...\n",
       "5     [(type, specimen, book), (specimen, book, surv...\n",
       "6     [(also, leap, electronic), (leap, electronic, ...\n",
       "7                 [(remaining, essentially, unchanged)]\n",
       "8     [(popularised, 1960s, release), (1960s, releas...\n",
       "9     [(sheets, containing, lorem), (containing, lor...\n",
       "10    [(desktop, publishing, software), (publishing,...\n",
       "11    [(including, versions, lorem), (versions, lore...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = tokenized_text_no_symbols.apply(lambda x: generate_ngrams(x, 3))\n",
    "trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431487e3",
   "metadata": {},
   "source": [
    "# Problem 2 : Stemming, Lemmatization, and WordSense Disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe4fbdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem Statement: Stemming, Lemmatization, and WordSense Disambiguation\n",
    "\n",
    "# Perform the following tasks to get an understanding of stemming,lemmatization andWord Sense Disambiguation (WSD) using the Natural LanguageTool Kit (NLTK) \n",
    "\n",
    "# 1.Declare   a   list   of   words   and   perform   stemming   on   each   word   using PorterStemmer() andLancasterStemmer()\n",
    "\n",
    "# 2.Declare a sentence and perform lemmatization on each word of the sentence using  WordNetLemmetizer()\n",
    "\n",
    "# 3.Declare two different sentences with homonyms and perform WSD to fetch the meanings of the homonyms in the context of their respective sentences\n",
    "\n",
    "# Note:Homonyms  are  words  with  the  exact  spelling  and  pronunciation  but different meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1b56444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run',\n",
       " 'ran',\n",
       " 'run',\n",
       " 'runner',\n",
       " 'runningli',\n",
       " 'happi',\n",
       " 'happi',\n",
       " 'happier',\n",
       " 'happiest']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Sample list of words\n",
    "words = [\"running\", \"ran\", \"runs\", \"runner\", \"runningly\", \"happiness\", \"happy\", \"happier\", \"happiest\"]\n",
    "\n",
    "# Initialize stemmers\n",
    "pst = PorterStemmer()\n",
    "lst = LancasterStemmer()\n",
    "\n",
    "porter_stemmed_words = [pst.stem(word) for word in words]\n",
    "porter_stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2a6bb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run', 'ran', 'run', 'run', 'run', 'happy', 'happy', 'happy', 'happiest']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster_stemmed_words = [lst.stem(word) for word in words]\n",
    "lancaster_stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27705bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " 'are',\n",
       " 'jumping',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazy',\n",
       " 'dog']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence\n",
    "sentence = \"The quick brown foxes are jumping over the lazy dogs\"\n",
    "\n",
    "words = sentence.split()\n",
    "\n",
    "# initialize\n",
    "wnlmt = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_words = [wnlmt.lemmatize(word) for word in words]\n",
    "lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "add51836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "\n",
    "# sentences with homonyms\n",
    "sentence1 = \"The bank by the river is full of fish.\"\n",
    "sentence2 = \"I need to deposit some money in the bank.\"\n",
    "\n",
    "# tokenize\n",
    "tokens1 = nltk.word_tokenize(sentence1)\n",
    "tokens2 = nltk.word_tokenize(sentence2)\n",
    "\n",
    "# Word Sense Disambiguation (WSD) for the word \"bank\" in both sentences\n",
    "bank1 = lesk(tokens1, 'bank')\n",
    "bank2 = lesk(tokens2, 'bank')\n",
    "\n",
    "bank1.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c580099e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a container (usually with a slot in the top) for keeping money at home'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank2.definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b62787",
   "metadata": {},
   "source": [
    "# Problem 3 : Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94a9bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem Statement:Feature Extraction\n",
    "\n",
    "# Write  a  Python  program  that  reads  the demotext2.txt text  file   and   thenthe   following   are   the   tasks   that   are   to   be   taken   into consideration while constructing the solution.\n",
    "\n",
    "# 1.Load the demotext2.txttext file into a variable and then close the file\n",
    "\n",
    "# 2.Do sentence wise tokenization and list out generated tokens\n",
    "\n",
    "# 3.Transform each token into a lower case\n",
    "\n",
    "# 4.Do vectorization using TFID Vectorizer\n",
    "\n",
    "# 5.Generate vector-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93e92644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He can even spout some sports trivia and Chris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We'd talk sports and stuff, and maybe have a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Admirable Crichton of his day, he was keen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But he was not brought forward by his father o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thankfully, he was too concerned with sports t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>See Strutt, Sports and Pastimes, who also give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>As they entered the yard, Carmen noticed Lori'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>After a lengthy shower, Jenn exited and pulled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A park and sports ground at the western end of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>There were crude medieval notions that fossils...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  He can even spout some sports trivia and Chris...\n",
       "1  We'd talk sports and stuff, and maybe have a b...\n",
       "2  The Admirable Crichton of his day, he was keen...\n",
       "3  But he was not brought forward by his father o...\n",
       "4  Thankfully, he was too concerned with sports t...\n",
       "5  See Strutt, Sports and Pastimes, who also give...\n",
       "6  As they entered the yard, Carmen noticed Lori'...\n",
       "7  After a lengthy shower, Jenn exited and pulled...\n",
       "8  A park and sports ground at the western end of...\n",
       "9  There were crude medieval notions that fossils..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"demotext2.txt\", delimiter=\"\\t\", header=None, names=[\"text\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0ed7c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He can even spout some sports trivia and Christmas carols and stuff like that.',\n",
       " \"We'd talk sports and stuff, and maybe have a beer.\",\n",
       " 'The Admirable Crichton of his day, he was keen alike on field sports and the arts, the friend and admirer equally of Cecil Rhodes and of Rodin, a railway director and a yeomanry colonel.',\n",
       " \"But he was not brought forward by his father or prepared in any way for his future greatness, and lived in the country occupied with field sports, till after the institution of the second protectorate in 16J7 and the recognition of Oliver's right to name his successor.\",\n",
       " 'Thankfully, he was too concerned with sports to get in any real trouble.',\n",
       " 'See Strutt, Sports and Pastimes, who also gives an illustration, \"taken from a manuscriptal painting of the 9th century in the Cotton Library,\" representing \"a Saxon chieftain, attended by his huntsman and a couple of hounds, pursuing the wild swine in a forest.\"',\n",
       " \"As they entered the yard, Carmen noticed Lori's little red sports car.\",\n",
       " 'After a lengthy shower, Jenn exited and pulled on clean leggings, sports bra, and socks.',\n",
       " 'A park and sports ground at the western end of the town contains the pedestal for a statue of President Kruger.',\n",
       " 'There were crude medieval notions that fossils were \" freaks \" or \" sports \" of nature (lusus naturae), or that they represented failures of a creative force within the earth (a notion of Greek and Arabic origin), or that larger and smaller fossils represented the remains of races of giants or of pygmies (the mythical idea).']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = data[\"text\"].tolist()\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12d9adfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['He',\n",
       "  'can',\n",
       "  'even',\n",
       "  'spout',\n",
       "  'some',\n",
       "  'sports',\n",
       "  'trivia',\n",
       "  'and',\n",
       "  'Christmas',\n",
       "  'carols',\n",
       "  'and',\n",
       "  'stuff',\n",
       "  'like',\n",
       "  'that.'],\n",
       " [\"We'd\",\n",
       "  'talk',\n",
       "  'sports',\n",
       "  'and',\n",
       "  'stuff,',\n",
       "  'and',\n",
       "  'maybe',\n",
       "  'have',\n",
       "  'a',\n",
       "  'beer.'],\n",
       " ['The',\n",
       "  'Admirable',\n",
       "  'Crichton',\n",
       "  'of',\n",
       "  'his',\n",
       "  'day,',\n",
       "  'he',\n",
       "  'was',\n",
       "  'keen',\n",
       "  'alike',\n",
       "  'on',\n",
       "  'field',\n",
       "  'sports',\n",
       "  'and',\n",
       "  'the',\n",
       "  'arts,',\n",
       "  'the',\n",
       "  'friend',\n",
       "  'and',\n",
       "  'admirer',\n",
       "  'equally',\n",
       "  'of',\n",
       "  'Cecil',\n",
       "  'Rhodes',\n",
       "  'and',\n",
       "  'of',\n",
       "  'Rodin,',\n",
       "  'a',\n",
       "  'railway',\n",
       "  'director',\n",
       "  'and',\n",
       "  'a',\n",
       "  'yeomanry',\n",
       "  'colonel.'],\n",
       " ['But',\n",
       "  'he',\n",
       "  'was',\n",
       "  'not',\n",
       "  'brought',\n",
       "  'forward',\n",
       "  'by',\n",
       "  'his',\n",
       "  'father',\n",
       "  'or',\n",
       "  'prepared',\n",
       "  'in',\n",
       "  'any',\n",
       "  'way',\n",
       "  'for',\n",
       "  'his',\n",
       "  'future',\n",
       "  'greatness,',\n",
       "  'and',\n",
       "  'lived',\n",
       "  'in',\n",
       "  'the',\n",
       "  'country',\n",
       "  'occupied',\n",
       "  'with',\n",
       "  'field',\n",
       "  'sports,',\n",
       "  'till',\n",
       "  'after',\n",
       "  'the',\n",
       "  'institution',\n",
       "  'of',\n",
       "  'the',\n",
       "  'second',\n",
       "  'protectorate',\n",
       "  'in',\n",
       "  '16J7',\n",
       "  'and',\n",
       "  'the',\n",
       "  'recognition',\n",
       "  'of',\n",
       "  \"Oliver's\",\n",
       "  'right',\n",
       "  'to',\n",
       "  'name',\n",
       "  'his',\n",
       "  'successor.'],\n",
       " ['Thankfully,',\n",
       "  'he',\n",
       "  'was',\n",
       "  'too',\n",
       "  'concerned',\n",
       "  'with',\n",
       "  'sports',\n",
       "  'to',\n",
       "  'get',\n",
       "  'in',\n",
       "  'any',\n",
       "  'real',\n",
       "  'trouble.'],\n",
       " ['See',\n",
       "  'Strutt,',\n",
       "  'Sports',\n",
       "  'and',\n",
       "  'Pastimes,',\n",
       "  'who',\n",
       "  'also',\n",
       "  'gives',\n",
       "  'an',\n",
       "  'illustration,',\n",
       "  '\"taken',\n",
       "  'from',\n",
       "  'a',\n",
       "  'manuscriptal',\n",
       "  'painting',\n",
       "  'of',\n",
       "  'the',\n",
       "  '9th',\n",
       "  'century',\n",
       "  'in',\n",
       "  'the',\n",
       "  'Cotton',\n",
       "  'Library,\"',\n",
       "  'representing',\n",
       "  '\"a',\n",
       "  'Saxon',\n",
       "  'chieftain,',\n",
       "  'attended',\n",
       "  'by',\n",
       "  'his',\n",
       "  'huntsman',\n",
       "  'and',\n",
       "  'a',\n",
       "  'couple',\n",
       "  'of',\n",
       "  'hounds,',\n",
       "  'pursuing',\n",
       "  'the',\n",
       "  'wild',\n",
       "  'swine',\n",
       "  'in',\n",
       "  'a',\n",
       "  'forest.\"'],\n",
       " ['As',\n",
       "  'they',\n",
       "  'entered',\n",
       "  'the',\n",
       "  'yard,',\n",
       "  'Carmen',\n",
       "  'noticed',\n",
       "  \"Lori's\",\n",
       "  'little',\n",
       "  'red',\n",
       "  'sports',\n",
       "  'car.'],\n",
       " ['After',\n",
       "  'a',\n",
       "  'lengthy',\n",
       "  'shower,',\n",
       "  'Jenn',\n",
       "  'exited',\n",
       "  'and',\n",
       "  'pulled',\n",
       "  'on',\n",
       "  'clean',\n",
       "  'leggings,',\n",
       "  'sports',\n",
       "  'bra,',\n",
       "  'and',\n",
       "  'socks.'],\n",
       " ['A',\n",
       "  'park',\n",
       "  'and',\n",
       "  'sports',\n",
       "  'ground',\n",
       "  'at',\n",
       "  'the',\n",
       "  'western',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  'town',\n",
       "  'contains',\n",
       "  'the',\n",
       "  'pedestal',\n",
       "  'for',\n",
       "  'a',\n",
       "  'statue',\n",
       "  'of',\n",
       "  'President',\n",
       "  'Kruger.'],\n",
       " ['There',\n",
       "  'were',\n",
       "  'crude',\n",
       "  'medieval',\n",
       "  'notions',\n",
       "  'that',\n",
       "  'fossils',\n",
       "  'were',\n",
       "  '\"',\n",
       "  'freaks',\n",
       "  '\"',\n",
       "  'or',\n",
       "  '\"',\n",
       "  'sports',\n",
       "  '\"',\n",
       "  'of',\n",
       "  'nature',\n",
       "  '(lusus',\n",
       "  'naturae),',\n",
       "  'or',\n",
       "  'that',\n",
       "  'they',\n",
       "  'represented',\n",
       "  'failures',\n",
       "  'of',\n",
       "  'a',\n",
       "  'creative',\n",
       "  'force',\n",
       "  'within',\n",
       "  'the',\n",
       "  'earth',\n",
       "  '(a',\n",
       "  'notion',\n",
       "  'of',\n",
       "  'Greek',\n",
       "  'and',\n",
       "  'Arabic',\n",
       "  'origin),',\n",
       "  'or',\n",
       "  'that',\n",
       "  'larger',\n",
       "  'and',\n",
       "  'smaller',\n",
       "  'fossils',\n",
       "  'represented',\n",
       "  'the',\n",
       "  'remains',\n",
       "  'of',\n",
       "  'races',\n",
       "  'of',\n",
       "  'giants',\n",
       "  'or',\n",
       "  'of',\n",
       "  'pygmies',\n",
       "  '(the',\n",
       "  'mythical',\n",
       "  'idea).']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens = [sentence.split() for sentence in sentences]\n",
    "sentence_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e7edfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['he',\n",
       "  'can',\n",
       "  'even',\n",
       "  'spout',\n",
       "  'some',\n",
       "  'sports',\n",
       "  'trivia',\n",
       "  'and',\n",
       "  'christmas',\n",
       "  'carols',\n",
       "  'and',\n",
       "  'stuff',\n",
       "  'like',\n",
       "  'that.'],\n",
       " [\"we'd\",\n",
       "  'talk',\n",
       "  'sports',\n",
       "  'and',\n",
       "  'stuff,',\n",
       "  'and',\n",
       "  'maybe',\n",
       "  'have',\n",
       "  'a',\n",
       "  'beer.'],\n",
       " ['the',\n",
       "  'admirable',\n",
       "  'crichton',\n",
       "  'of',\n",
       "  'his',\n",
       "  'day,',\n",
       "  'he',\n",
       "  'was',\n",
       "  'keen',\n",
       "  'alike',\n",
       "  'on',\n",
       "  'field',\n",
       "  'sports',\n",
       "  'and',\n",
       "  'the',\n",
       "  'arts,',\n",
       "  'the',\n",
       "  'friend',\n",
       "  'and',\n",
       "  'admirer',\n",
       "  'equally',\n",
       "  'of',\n",
       "  'cecil',\n",
       "  'rhodes',\n",
       "  'and',\n",
       "  'of',\n",
       "  'rodin,',\n",
       "  'a',\n",
       "  'railway',\n",
       "  'director',\n",
       "  'and',\n",
       "  'a',\n",
       "  'yeomanry',\n",
       "  'colonel.'],\n",
       " ['but',\n",
       "  'he',\n",
       "  'was',\n",
       "  'not',\n",
       "  'brought',\n",
       "  'forward',\n",
       "  'by',\n",
       "  'his',\n",
       "  'father',\n",
       "  'or',\n",
       "  'prepared',\n",
       "  'in',\n",
       "  'any',\n",
       "  'way',\n",
       "  'for',\n",
       "  'his',\n",
       "  'future',\n",
       "  'greatness,',\n",
       "  'and',\n",
       "  'lived',\n",
       "  'in',\n",
       "  'the',\n",
       "  'country',\n",
       "  'occupied',\n",
       "  'with',\n",
       "  'field',\n",
       "  'sports,',\n",
       "  'till',\n",
       "  'after',\n",
       "  'the',\n",
       "  'institution',\n",
       "  'of',\n",
       "  'the',\n",
       "  'second',\n",
       "  'protectorate',\n",
       "  'in',\n",
       "  '16j7',\n",
       "  'and',\n",
       "  'the',\n",
       "  'recognition',\n",
       "  'of',\n",
       "  \"oliver's\",\n",
       "  'right',\n",
       "  'to',\n",
       "  'name',\n",
       "  'his',\n",
       "  'successor.'],\n",
       " ['thankfully,',\n",
       "  'he',\n",
       "  'was',\n",
       "  'too',\n",
       "  'concerned',\n",
       "  'with',\n",
       "  'sports',\n",
       "  'to',\n",
       "  'get',\n",
       "  'in',\n",
       "  'any',\n",
       "  'real',\n",
       "  'trouble.'],\n",
       " ['see',\n",
       "  'strutt,',\n",
       "  'sports',\n",
       "  'and',\n",
       "  'pastimes,',\n",
       "  'who',\n",
       "  'also',\n",
       "  'gives',\n",
       "  'an',\n",
       "  'illustration,',\n",
       "  '\"taken',\n",
       "  'from',\n",
       "  'a',\n",
       "  'manuscriptal',\n",
       "  'painting',\n",
       "  'of',\n",
       "  'the',\n",
       "  '9th',\n",
       "  'century',\n",
       "  'in',\n",
       "  'the',\n",
       "  'cotton',\n",
       "  'library,\"',\n",
       "  'representing',\n",
       "  '\"a',\n",
       "  'saxon',\n",
       "  'chieftain,',\n",
       "  'attended',\n",
       "  'by',\n",
       "  'his',\n",
       "  'huntsman',\n",
       "  'and',\n",
       "  'a',\n",
       "  'couple',\n",
       "  'of',\n",
       "  'hounds,',\n",
       "  'pursuing',\n",
       "  'the',\n",
       "  'wild',\n",
       "  'swine',\n",
       "  'in',\n",
       "  'a',\n",
       "  'forest.\"'],\n",
       " ['as',\n",
       "  'they',\n",
       "  'entered',\n",
       "  'the',\n",
       "  'yard,',\n",
       "  'carmen',\n",
       "  'noticed',\n",
       "  \"lori's\",\n",
       "  'little',\n",
       "  'red',\n",
       "  'sports',\n",
       "  'car.'],\n",
       " ['after',\n",
       "  'a',\n",
       "  'lengthy',\n",
       "  'shower,',\n",
       "  'jenn',\n",
       "  'exited',\n",
       "  'and',\n",
       "  'pulled',\n",
       "  'on',\n",
       "  'clean',\n",
       "  'leggings,',\n",
       "  'sports',\n",
       "  'bra,',\n",
       "  'and',\n",
       "  'socks.'],\n",
       " ['a',\n",
       "  'park',\n",
       "  'and',\n",
       "  'sports',\n",
       "  'ground',\n",
       "  'at',\n",
       "  'the',\n",
       "  'western',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  'town',\n",
       "  'contains',\n",
       "  'the',\n",
       "  'pedestal',\n",
       "  'for',\n",
       "  'a',\n",
       "  'statue',\n",
       "  'of',\n",
       "  'president',\n",
       "  'kruger.'],\n",
       " ['there',\n",
       "  'were',\n",
       "  'crude',\n",
       "  'medieval',\n",
       "  'notions',\n",
       "  'that',\n",
       "  'fossils',\n",
       "  'were',\n",
       "  '\"',\n",
       "  'freaks',\n",
       "  '\"',\n",
       "  'or',\n",
       "  '\"',\n",
       "  'sports',\n",
       "  '\"',\n",
       "  'of',\n",
       "  'nature',\n",
       "  '(lusus',\n",
       "  'naturae),',\n",
       "  'or',\n",
       "  'that',\n",
       "  'they',\n",
       "  'represented',\n",
       "  'failures',\n",
       "  'of',\n",
       "  'a',\n",
       "  'creative',\n",
       "  'force',\n",
       "  'within',\n",
       "  'the',\n",
       "  'earth',\n",
       "  '(a',\n",
       "  'notion',\n",
       "  'of',\n",
       "  'greek',\n",
       "  'and',\n",
       "  'arabic',\n",
       "  'origin),',\n",
       "  'or',\n",
       "  'that',\n",
       "  'larger',\n",
       "  'and',\n",
       "  'smaller',\n",
       "  'fossils',\n",
       "  'represented',\n",
       "  'the',\n",
       "  'remains',\n",
       "  'of',\n",
       "  'races',\n",
       "  'of',\n",
       "  'giants',\n",
       "  'or',\n",
       "  'of',\n",
       "  'pygmies',\n",
       "  '(the',\n",
       "  'mythical',\n",
       "  'idea).']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens_lower = [[token.lower() for token in tokens] for tokens in sentence_tokens]\n",
    "sentence_tokens_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ddc4627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f05ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix =tfidf.fit_transform(data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d00397e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x161 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 207 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc96e12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.18882823, ..., 0.        , 0.        ,\n",
       "        0.18882823],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.11784944, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_matrix = tfidf_matrix.toarray()\n",
    "vector_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b83f40e",
   "metadata": {},
   "source": [
    "# Problem 4 : Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef9e2ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem Statement: Sentiment Analysis\n",
    "\n",
    "# Write  a  Python  program  that  reads  the mood_data.txtfile into a DataFrame. Then the following the given tasks, that has to be taken into consideration while constructing the solution.Here dataset contains two columns where one is our target (“emotion” has 6 different categories) and another is the independent variable (“Text” contains data in form of sentences).\n",
    "\n",
    "# 1.Load the mobile mood_data.txtdata into a DataFrame\n",
    "\n",
    "# 2.Generate tokens and remove punctuations, stop words and lower all rows\n",
    "\n",
    "# 3.Join  all  the  tokens  as  they  were  before  and  store them  in  a  new  column named “cleaned_text” \n",
    "\n",
    "# 4.Now  remove  all  single  characters,  extra  space,  and  special  characters  and store processed data in a new column named “processed_text” \n",
    "\n",
    "# 5.Create  a  final  DataFrame  containing  dependent  variable(emotion)  and processed text\n",
    "\n",
    "# 6.Extract   independent   variables   (Xs)   and   dependent   variables   (Ys)   into separate data objects\n",
    "\n",
    "# 7.Generate tokens and do vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1f58b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated;sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy;anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall;joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0                        i didnt feel humiliated;sadness\n",
       "1      i can go from feeling so hopeless to so damned...\n",
       "2      im grabbing a minute to post i feel greedy wro...\n",
       "3      i am ever feeling nostalgic about the fireplac...\n",
       "4                             i am feeling grouchy;anger\n",
       "...                                                  ...\n",
       "15995  i just had a very brief time in the beanbag an...\n",
       "15996  i am now turning and i feel pathetic that i am...\n",
       "15997                 i feel strong and good overall;joy\n",
       "15998  i feel like this was such a rude comment and i...\n",
       "15999  i know a lot but i feel so stupid because i ca...\n",
       "\n",
       "[16000 rows x 1 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"mood_data.txt\", delimiter=\"\\t\", header=None, names=[\"text\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "15c1452c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       [didnt, feel, humiliated, sadness]\n",
       "1        [go, feeling, hopeless, damned, hopeful, aroun...\n",
       "2        [im, grabbing, minute, post, feel, greedy, wro...\n",
       "3        [ever, feeling, nostalgic, fireplace, know, st...\n",
       "4                                [feeling, grouchy, anger]\n",
       "                               ...                        \n",
       "15995    [brief, time, beanbag, said, anna, feel, like,...\n",
       "15996    [turning, feel, pathetic, still, waiting, tabl...\n",
       "15997                   [feel, strong, good, overall, joy]\n",
       "15998         [feel, like, rude, comment, im, glad, anger]\n",
       "15999          [know, lot, feel, stupid, portray, sadness]\n",
       "Name: text, Length: 16000, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import string\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# fn to preprocess (tokenize -> lowercase -> remove stopwords)\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()] #check for alphabets only\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "data[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "579ddfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated;sadness</td>\n",
       "      <td>[didnt, feel, humiliated, sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>[go, feeling, hopeless, damned, hopeful, aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wro...</td>\n",
       "      <td>[im, grabbing, minute, post, feel, greedy, wro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>[ever, feeling, nostalgic, fireplace, know, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy;anger</td>\n",
       "      <td>[feeling, grouchy, anger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>[brief, time, beanbag, said, anna, feel, like,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>[turning, feel, pathetic, still, waiting, tabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall;joy</td>\n",
       "      <td>[feel, strong, good, overall, joy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>[feel, like, rude, comment, im, glad, anger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>[know, lot, feel, stupid, portray, sadness]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0                        i didnt feel humiliated;sadness   \n",
       "1      i can go from feeling so hopeless to so damned...   \n",
       "2      im grabbing a minute to post i feel greedy wro...   \n",
       "3      i am ever feeling nostalgic about the fireplac...   \n",
       "4                             i am feeling grouchy;anger   \n",
       "...                                                  ...   \n",
       "15995  i just had a very brief time in the beanbag an...   \n",
       "15996  i am now turning and i feel pathetic that i am...   \n",
       "15997                 i feel strong and good overall;joy   \n",
       "15998  i feel like this was such a rude comment and i...   \n",
       "15999  i know a lot but i feel so stupid because i ca...   \n",
       "\n",
       "                                                  tokens  \n",
       "0                     [didnt, feel, humiliated, sadness]  \n",
       "1      [go, feeling, hopeless, damned, hopeful, aroun...  \n",
       "2      [im, grabbing, minute, post, feel, greedy, wro...  \n",
       "3      [ever, feeling, nostalgic, fireplace, know, st...  \n",
       "4                              [feeling, grouchy, anger]  \n",
       "...                                                  ...  \n",
       "15995  [brief, time, beanbag, said, anna, feel, like,...  \n",
       "15996  [turning, feel, pathetic, still, waiting, tabl...  \n",
       "15997                 [feel, strong, good, overall, joy]  \n",
       "15998       [feel, like, rude, comment, im, glad, anger]  \n",
       "15999        [know, lot, feel, stupid, portray, sadness]  \n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tokens\"] = data[\"text\"].apply(preprocess_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a05fe8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated;sadness</td>\n",
       "      <td>[didnt, feel, humiliated, sadness]</td>\n",
       "      <td>didnt feel humiliated sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>[go, feeling, hopeless, damned, hopeful, aroun...</td>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wro...</td>\n",
       "      <td>[im, grabbing, minute, post, feel, greedy, wro...</td>\n",
       "      <td>im grabbing minute post feel greedy wrong anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>[ever, feeling, nostalgic, fireplace, know, st...</td>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy;anger</td>\n",
       "      <td>[feeling, grouchy, anger]</td>\n",
       "      <td>feeling grouchy anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>[brief, time, beanbag, said, anna, feel, like,...</td>\n",
       "      <td>brief time beanbag said anna feel like beaten ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>[turning, feel, pathetic, still, waiting, tabl...</td>\n",
       "      <td>turning feel pathetic still waiting tables sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall;joy</td>\n",
       "      <td>[feel, strong, good, overall, joy]</td>\n",
       "      <td>feel strong good overall joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>[feel, like, rude, comment, im, glad, anger]</td>\n",
       "      <td>feel like rude comment im glad anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>[know, lot, feel, stupid, portray, sadness]</td>\n",
       "      <td>know lot feel stupid portray sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0                        i didnt feel humiliated;sadness   \n",
       "1      i can go from feeling so hopeless to so damned...   \n",
       "2      im grabbing a minute to post i feel greedy wro...   \n",
       "3      i am ever feeling nostalgic about the fireplac...   \n",
       "4                             i am feeling grouchy;anger   \n",
       "...                                                  ...   \n",
       "15995  i just had a very brief time in the beanbag an...   \n",
       "15996  i am now turning and i feel pathetic that i am...   \n",
       "15997                 i feel strong and good overall;joy   \n",
       "15998  i feel like this was such a rude comment and i...   \n",
       "15999  i know a lot but i feel so stupid because i ca...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0                     [didnt, feel, humiliated, sadness]   \n",
       "1      [go, feeling, hopeless, damned, hopeful, aroun...   \n",
       "2      [im, grabbing, minute, post, feel, greedy, wro...   \n",
       "3      [ever, feeling, nostalgic, fireplace, know, st...   \n",
       "4                              [feeling, grouchy, anger]   \n",
       "...                                                  ...   \n",
       "15995  [brief, time, beanbag, said, anna, feel, like,...   \n",
       "15996  [turning, feel, pathetic, still, waiting, tabl...   \n",
       "15997                 [feel, strong, good, overall, joy]   \n",
       "15998       [feel, like, rude, comment, im, glad, anger]   \n",
       "15999        [know, lot, feel, stupid, portray, sadness]   \n",
       "\n",
       "                                            cleaned_text  \n",
       "0                          didnt feel humiliated sadness  \n",
       "1      go feeling hopeless damned hopeful around some...  \n",
       "2        im grabbing minute post feel greedy wrong anger  \n",
       "3      ever feeling nostalgic fireplace know still pr...  \n",
       "4                                  feeling grouchy anger  \n",
       "...                                                  ...  \n",
       "15995  brief time beanbag said anna feel like beaten ...  \n",
       "15996  turning feel pathetic still waiting tables sub...  \n",
       "15997                       feel strong good overall joy  \n",
       "15998               feel like rude comment im glad anger  \n",
       "15999               know lot feel stupid portray sadness  \n",
       "\n",
       "[16000 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"cleaned_text\"] = data[\"tokens\"].apply(lambda x: \" \".join(x))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c7648596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated;sadness</td>\n",
       "      <td>[didnt, feel, humiliated, sadness]</td>\n",
       "      <td>didnt feel humiliated sadness</td>\n",
       "      <td>didnt feel humiliated sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>[go, feeling, hopeless, damned, hopeful, aroun...</td>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wro...</td>\n",
       "      <td>[im, grabbing, minute, post, feel, greedy, wro...</td>\n",
       "      <td>im grabbing minute post feel greedy wrong anger</td>\n",
       "      <td>im grabbing minute post feel greedy wrong anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>[ever, feeling, nostalgic, fireplace, know, st...</td>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy;anger</td>\n",
       "      <td>[feeling, grouchy, anger]</td>\n",
       "      <td>feeling grouchy anger</td>\n",
       "      <td>feeling grouchy anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>[brief, time, beanbag, said, anna, feel, like,...</td>\n",
       "      <td>brief time beanbag said anna feel like beaten ...</td>\n",
       "      <td>brief time beanbag said anna feel like beaten ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>[turning, feel, pathetic, still, waiting, tabl...</td>\n",
       "      <td>turning feel pathetic still waiting tables sub...</td>\n",
       "      <td>turning feel pathetic still waiting tables sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall;joy</td>\n",
       "      <td>[feel, strong, good, overall, joy]</td>\n",
       "      <td>feel strong good overall joy</td>\n",
       "      <td>feel strong good overall joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>[feel, like, rude, comment, im, glad, anger]</td>\n",
       "      <td>feel like rude comment im glad anger</td>\n",
       "      <td>feel like rude comment im glad anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>[know, lot, feel, stupid, portray, sadness]</td>\n",
       "      <td>know lot feel stupid portray sadness</td>\n",
       "      <td>know lot feel stupid portray sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0                        i didnt feel humiliated;sadness   \n",
       "1      i can go from feeling so hopeless to so damned...   \n",
       "2      im grabbing a minute to post i feel greedy wro...   \n",
       "3      i am ever feeling nostalgic about the fireplac...   \n",
       "4                             i am feeling grouchy;anger   \n",
       "...                                                  ...   \n",
       "15995  i just had a very brief time in the beanbag an...   \n",
       "15996  i am now turning and i feel pathetic that i am...   \n",
       "15997                 i feel strong and good overall;joy   \n",
       "15998  i feel like this was such a rude comment and i...   \n",
       "15999  i know a lot but i feel so stupid because i ca...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0                     [didnt, feel, humiliated, sadness]   \n",
       "1      [go, feeling, hopeless, damned, hopeful, aroun...   \n",
       "2      [im, grabbing, minute, post, feel, greedy, wro...   \n",
       "3      [ever, feeling, nostalgic, fireplace, know, st...   \n",
       "4                              [feeling, grouchy, anger]   \n",
       "...                                                  ...   \n",
       "15995  [brief, time, beanbag, said, anna, feel, like,...   \n",
       "15996  [turning, feel, pathetic, still, waiting, tabl...   \n",
       "15997                 [feel, strong, good, overall, joy]   \n",
       "15998       [feel, like, rude, comment, im, glad, anger]   \n",
       "15999        [know, lot, feel, stupid, portray, sadness]   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "0                          didnt feel humiliated sadness   \n",
       "1      go feeling hopeless damned hopeful around some...   \n",
       "2        im grabbing minute post feel greedy wrong anger   \n",
       "3      ever feeling nostalgic fireplace know still pr...   \n",
       "4                                  feeling grouchy anger   \n",
       "...                                                  ...   \n",
       "15995  brief time beanbag said anna feel like beaten ...   \n",
       "15996  turning feel pathetic still waiting tables sub...   \n",
       "15997                       feel strong good overall joy   \n",
       "15998               feel like rude comment im glad anger   \n",
       "15999               know lot feel stupid portray sadness   \n",
       "\n",
       "                                          processed_text  \n",
       "0                          didnt feel humiliated sadness  \n",
       "1      go feeling hopeless damned hopeful around some...  \n",
       "2        im grabbing minute post feel greedy wrong anger  \n",
       "3      ever feeling nostalgic fireplace know still pr...  \n",
       "4                                  feeling grouchy anger  \n",
       "...                                                  ...  \n",
       "15995  brief time beanbag said anna feel like beaten ...  \n",
       "15996  turning feel pathetic still waiting tables sub...  \n",
       "15997                       feel strong good overall joy  \n",
       "15998               feel like rude comment im glad anger  \n",
       "15999               know lot feel stupid portray sadness  \n",
       "\n",
       "[16000 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fn to processs (remove all single characters, extra space, and special characters\n",
    "def process_text(text):\n",
    "    processed_text = \" \".join([word for word in text.split() if len(word) > 1])\n",
    "    return processed_text\n",
    "\n",
    "# store processed data in a new column named “processed_text”\n",
    "data[\"processed_text\"] = data[\"cleaned_text\"].apply(process_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08098671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>brief time beanbag said anna feel like beaten ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>turning feel pathetic still waiting tables sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>feel strong good overall joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>feel like rude comment im glad anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>know lot feel stupid portray sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          processed_text\n",
       "0                          didnt feel humiliated sadness\n",
       "1      go feeling hopeless damned hopeful around some...\n",
       "2        im grabbing minute post feel greedy wrong anger\n",
       "3      ever feeling nostalgic fireplace know still pr...\n",
       "4                                  feeling grouchy anger\n",
       "...                                                  ...\n",
       "15995  brief time beanbag said anna feel like beaten ...\n",
       "15996  turning feel pathetic still waiting tables sub...\n",
       "15997                       feel strong good overall joy\n",
       "15998               feel like rude comment im glad anger\n",
       "15999               know lot feel stupid portray sadness\n",
       "\n",
       "[16000 rows x 1 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a final DataFrame containing dependent variable (emotion) and processed text\n",
    "final_data = data[[\"processed_text\"]]\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ed48d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/frtzry9s6b32vg4gz127642h0000gn/T/ipykernel_2427/2607236431.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data[\"emotion\"] = data[\"text\"].apply(lambda x: x.split(\";\")[1])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>brief time beanbag said anna feel like beaten ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>turning feel pathetic still waiting tables sub...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>feel strong good overall joy</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>feel like rude comment im glad anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>know lot feel stupid portray sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          processed_text  emotion\n",
       "0                          didnt feel humiliated sadness  sadness\n",
       "1      go feeling hopeless damned hopeful around some...  sadness\n",
       "2        im grabbing minute post feel greedy wrong anger    anger\n",
       "3      ever feeling nostalgic fireplace know still pr...     love\n",
       "4                                  feeling grouchy anger    anger\n",
       "...                                                  ...      ...\n",
       "15995  brief time beanbag said anna feel like beaten ...  sadness\n",
       "15996  turning feel pathetic still waiting tables sub...  sadness\n",
       "15997                       feel strong good overall joy      joy\n",
       "15998               feel like rude comment im glad anger    anger\n",
       "15999               know lot feel stupid portray sadness  sadness\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[\"emotion\"] = data[\"text\"].apply(lambda x: x.split(\";\")[1])\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58ffe8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            didnt feel humiliated sadness\n",
       "1        go feeling hopeless damned hopeful around some...\n",
       "2          im grabbing minute post feel greedy wrong anger\n",
       "3        ever feeling nostalgic fireplace know still pr...\n",
       "4                                    feeling grouchy anger\n",
       "                               ...                        \n",
       "15995    brief time beanbag said anna feel like beaten ...\n",
       "15996    turning feel pathetic still waiting tables sub...\n",
       "15997                         feel strong good overall joy\n",
       "15998                 feel like rude comment im glad anger\n",
       "15999                 know lot feel stupid portray sadness\n",
       "Name: processed_text, Length: 16000, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# independent variable\n",
    "x = final_data[\"processed_text\"]\n",
    "# dependent variable\n",
    "y = final_data[\"emotion\"]\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4277e456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        sadness\n",
       "1        sadness\n",
       "2          anger\n",
       "3           love\n",
       "4          anger\n",
       "          ...   \n",
       "15995    sadness\n",
       "15996    sadness\n",
       "15997        joy\n",
       "15998      anger\n",
       "15999    sadness\n",
       "Name: emotion, Length: 16000, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "35cbb49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16000x15044 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 160613 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "x_tfidf = tfidf.fit_transform(x)\n",
    "x_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3503b1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90822a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
